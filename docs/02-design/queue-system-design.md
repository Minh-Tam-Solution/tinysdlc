# TinySDLC - Queue System Design

**SDLC Version**: 6.1.0
**Stage**: 02 - DESIGN
**Status**: Active
**Authority**: CTO Approved

---

<!-- Originally: docs/QUEUE.md -->

TinySDLC uses a file-based queue system to coordinate message processing across multiple channels and agents. This document explains how it works.

## Overview

The queue system acts as a central coordinator between:
- **Channel clients** (Discord, Telegram, WhatsApp) - produce messages
- **Queue processor** - routes and processes messages
- **AI providers** (Claude, Codex) - generate responses
- **Agents** - isolated AI agents with different configs

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Legacy Channel Clients                        â”‚
â”‚         (Discord, Telegram, WhatsApp, Heartbeat)            â”‚
â”‚         src/channels/{discord,telegram,whatsapp}-client.ts  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ Write message.json directly
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ChannelPlugin Bridge (S03 upgrade)              â”‚
â”‚      (Zalo OA, Zalo Personal â€” src/channels/plugins/)       â”‚
â”‚                                                              â”‚
â”‚  plugin.onMessage() â”€â”€â†’ writeMessageToIncoming()            â”‚
â”‚                                                              â”‚
â”‚  deliverPluginResponses() â†â”€â”€ poll queue/outgoing/          â”‚
â”‚       â†“                                                      â”‚
â”‚  plugin.sendMessage(chatId, text)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Write / Read message.json
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ~/.tinysdlc/queue/                         â”‚
â”‚                                                              â”‚
â”‚  incoming/          processing/         outgoing/           â”‚
â”‚  â”œâ”€ msg1.json  â†’   â”œâ”€ msg1.json   â†’   â”œâ”€ msg1.json        â”‚
â”‚  â”œâ”€ msg2.json       â””â”€ msg2.json       â””â”€ msg2.json        â”‚
â”‚  â””â”€ msg3.json                                                â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ Queue Processor
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Parallel Processing by Agent                    â”‚
â”‚                                                              â”‚
â”‚  Agent: coder        Agent: writer       Agent: assistant   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ Message 1â”‚       â”‚ Message 1â”‚        â”‚ Message 1â”‚       â”‚
â”‚  â”‚ Message 2â”‚ ...   â”‚ Message 2â”‚  ...   â”‚ Message 2â”‚ ...   â”‚
â”‚  â”‚ Message 3â”‚       â”‚          â”‚        â”‚          â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜       â”‚
â”‚       â”‚                  â”‚                     â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“                  â†“                     â†“
   claude CLI         claude CLI             claude CLI
  (workspace/coder)  (workspace/writer)  (workspace/assistant)
```

## Directory Structure

```
~/.tinysdlc/
â”œâ”€â”€ queue/
â”‚   â”œâ”€â”€ incoming/          # New messages from channels
â”‚   â”‚   â”œâ”€â”€ msg_123456.json
â”‚   â”‚   â””â”€â”€ msg_789012.json
â”‚   â”œâ”€â”€ processing/        # Currently being processed
â”‚   â”‚   â””â”€â”€ msg_123456.json
â”‚   â””â”€â”€ outgoing/          # Responses ready to send
â”‚       â””â”€â”€ msg_123456.json
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ queue.log         # Queue processor logs
â”‚   â”œâ”€â”€ discord.log       # Channel-specific logs
â”‚   â””â”€â”€ telegram.log
â””â”€â”€ files/                # Uploaded files from channels
    â””â”€â”€ image_123.png
```

## Message Flow

### 1. Incoming Message

A channel client receives a message and writes it to `incoming/`:

```json
{
  "channel": "discord",
  "sender": "Alice",
  "senderId": "user_12345",
  "message": "@coder fix the authentication bug",
  "timestamp": 1707739200000,
  "messageId": "discord_msg_123",
  "files": ["/path/to/screenshot.png"]
}
```

**Optional fields:**
- `agent` - Pre-route to specific agent (bypasses @agent_id parsing)
- `files` - Array of file paths uploaded with message

### 2. Processing

The queue processor (runs every 1 second):

1. **Scans `incoming/`** for new messages
2. **Sorts by timestamp** (oldest first)
3. **Determines target agent**:
   - Checks `agent` field (if pre-routed)
   - Parses `@agent_id` prefix from message
   - Falls back to `default` agent
4. **Moves to `processing/`** (atomic operation)
5. **Routes to agent's promise chain** (parallel processing)

### 3. Agent Processing

Each agent has its own promise chain:

```typescript
// Messages to same agent = sequential (preserve conversation order)
agentChain: msg1 â†’ msg2 â†’ msg3

// Different agents = parallel (don't block each other)
@coder:     msg1 â”€â”€â”
@writer:    msg1 â”€â”€â”¼â”€â†’ All run concurrently
@assistant: msg1 â”€â”€â”˜
```

**Per-agent isolation:**
- Each agent runs in its own `working_directory`
- Separate conversation history (managed by CLI)
- Independent reset flags
- Own configuration files (.claude/, AGENTS.md)

### 4. AI Provider Execution

**Claude (Anthropic):**
```bash
cd ~/workspace/coder/
claude --dangerously-skip-permissions \
  --model claude-sonnet-4-5 \
  -c \  # Continue conversation
  -p "fix the authentication bug"
```

**Codex (OpenAI):**
```bash
cd ~/workspace/coder/
codex exec resume --last \
  --model gpt-5.3-codex \
  --skip-git-repo-check \
  --dangerously-bypass-approvals-and-sandbox \
  --json "fix the authentication bug"
```

### 5. Response

After AI responds, queue processor writes to `outgoing/`:

```json
{
  "channel": "discord",
  "sender": "Alice",
  "message": "I've identified the issue in auth.ts:42...",
  "originalMessage": "@coder fix the authentication bug",
  "timestamp": 1707739205000,
  "messageId": "discord_msg_123",
  "agent": "coder",
  "files": ["/path/to/fix.patch"]
}
```

### 6. Channel Delivery

Channel clients poll `outgoing/` and:
1. Read response for their channel
2. Send message to user
3. Delete the JSON file
4. Handle any file attachments

## Parallel Processing

### How It Works

Each agent has its own **promise chain** that processes messages sequentially:

```typescript
const agentProcessingChains = new Map<string, Promise<void>>();

// When message arrives for @coder:
const chain = agentProcessingChains.get('coder') || Promise.resolve();
const newChain = chain.then(() => processMessage(msg));
agentProcessingChains.set('coder', newChain);
```

### Benefits

**Example: 3 messages sent simultaneously**

Sequential (old):
```
@coder fix bug 1     [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 30s
@writer docs         [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 20s
@assistant help      [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 15s
Total: 65 seconds
```

Parallel (new):
```
@coder fix bug 1     [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 30s
@writer docs         [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 20s â† concurrent!
@assistant help      [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 15s   â† concurrent!
Total: 30 seconds (2.2x faster!)
```

### Conversation Order Preserved

Messages to the **same agent** remain sequential:

```
@coder fix bug 1     [â–ˆâ–ˆâ–ˆâ–ˆ] 10s
@coder fix bug 2             [â–ˆâ–ˆâ–ˆâ–ˆ] 10s  â† waits for bug 1
@writer docs         [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 15s        â† parallel with both
```

This ensures:
- âœ… Conversation context is maintained
- âœ… `-c` (continue) flag works correctly
- âœ… No race conditions within an agent
- âœ… Agents don't block each other

## Agent Routing

### Explicit Routing

Use `@agent_id` prefix:

```
User: @coder fix the login bug
â†’ Routes to agent "coder"
â†’ Message becomes: "fix the login bug"
```

### Pre-routing

Channel clients can pre-route:

```typescript
const queueData = {
  channel: 'discord',
  message: 'help me',
  agent: 'assistant'  // Pre-routed, no @prefix needed
};
```

### Fallback Logic

```
1. Check message.agent field (if pre-routed)
2. Parse @agent_id from message text
3. Look up agent in settings.agents
4. Fall back to 'default' agent
5. If no default, use first available agent
```

### Routing Examples

```
"@coder fix bug"           â†’ agent: coder
"help me"                  â†’ agent: default
"@unknown test"            â†’ agent: default (unknown agent)
"@assistant help"          â†’ agent: assistant
pre-routed with agent=X    â†’ agent: X
```

### Easter Egg: Multiple Agents ğŸ¥š

If you mention multiple agents in one message:

```
User: "@coder @writer fix this bug and document it"

Result:
  â†’ Returns friendly message about upcoming agent-to-agent collaboration
  â†’ No AI processing (saves tokens!)
  â†’ Suggests sending separate messages to each agent
```

**The easter egg message:**
> ğŸš€ **Agent-to-Agent Collaboration - Coming Soon!**
>
> You mentioned multiple agents: @coder, @writer
>
> Right now, I can only route to one agent at a time. But we're working on something cool:
>
> âœ¨ **Multi-Agent Coordination** - Agents will be able to collaborate on complex tasks!
> âœ¨ **Smart Routing** - Send instructions to multiple agents at once!
> âœ¨ **Agent Handoffs** - One agent can delegate to another!
>
> For now, please send separate messages to each agent:
> â€¢ `@coder [your message]`
> â€¢ `@writer [your message]`
>
> _Stay tuned for updates! ğŸ‰_

This prevents confusion and teases the upcoming feature!

## Reset System

### Per-Agent Reset

Creates `<workspace>/<agent_id>/reset_flag`:

```bash
tinysdlc reset coder
tinysdlc reset coder researcher    # reset multiple agents
tinysdlc agent reset coder
# Or in chat:
/reset @coder
/reset @coder @researcher
```

Next message to **that agent** starts fresh.

### How Resets Work

Queue processor checks before each message:

```typescript
const agentReset = fs.existsSync(`${agentDir}/reset_flag`);

if (agentReset) {
  // Don't pass -c flag to CLI
  // Delete flag file
}
```

## File Handling

### Uploading Files

Channels download files to `~/.tinysdlc/files/`:

```
User uploads: image.png
â†’ Saved as: ~/.tinysdlc/files/telegram_123_image.png
â†’ Message includes: [file: /absolute/path/to/image.png]
```

### Sending Files

AI can send files back:

```
AI response: "Here's the diagram [send_file: /path/to/diagram.png]"
â†’ Queue processor extracts file path
â†’ Adds to response.files array
â†’ Channel client sends as attachment
â†’ Tag is stripped from message text
```

## Error Handling

### Missing Agents

If agent not found:
```
User: @unknown help
â†’ Routes to: default agent
â†’ Logs: WARNING - Agent 'unknown' not found, using 'default'
```

### Processing Errors

Errors are caught per-agent:

```typescript
newChain.catch(error => {
  log('ERROR', `Error processing message for agent ${agentId}: ${error.message}`);
});
```

Failed messages:
- Don't block other agents
- Are logged to `queue.log`
- Response file not created
- Channel client times out gracefully

### Stale Messages

Orphaned files in `processing/` (from crash mid-process):
- On startup, `recoverOrphanedFiles()` moves them back to `incoming/` via `fs.renameSync`
- They are then re-processed from scratch on the next poll cycle

## Performance

### Throughput

- **Sequential**: 1 message per AI response time (~10-30s)
- **Parallel**: N agents Ã— 1 message per response time
- **3 agents**: ~3x throughput improvement

### Latency

- Queue check: Every 1 second
- Agent routing: <1ms (file peek)
- Max latency: 1s + AI response time

### Scaling

**Good for:**
- âœ… Multiple independent agents
- âœ… High message volume
- âœ… Long AI response times

**Limitations:**
- âš ï¸ File-based (not database)
- âš ï¸ Single queue processor instance
- âš ï¸ All agents on same machine

## Debugging

### Check Queue Status

```bash
# See pending messages
ls ~/.tinysdlc/queue/incoming/

# See processing
ls ~/.tinysdlc/queue/processing/

# See responses waiting
ls ~/.tinysdlc/queue/outgoing/

# Watch queue logs
tail -f ~/.tinysdlc/logs/queue.log
```

### Common Issues

**Messages stuck in incoming:**
- Queue processor not running
- Check: `tinysdlc status`

**Messages stuck in processing:**
- AI CLI crashed or hung
- Manual cleanup: `rm ~/.tinysdlc/queue/processing/*`
- Restart: `tinysdlc restart`

**No responses generated:**
- Check agent routing (wrong @agent_id?)
- Check AI CLI is installed (claude/codex)
- Check logs: `tail -f ~/.tinysdlc/logs/queue.log`

**Agents not processing in parallel:**
- Check TypeScript build: `npm run build`
- Check queue processor version in logs

## Advanced Topics

### Custom Queue Implementations

Replace file-based queue with:
- Redis (for multi-instance)
- Database (for persistence)
- Message broker (RabbitMQ, Kafka)

Key interface to maintain:
```typescript
interface QueueMessage {
  channel: string;
  sender: string;
  message: string;
  timestamp: number;
  messageId: string;
  agent?: string;
  files?: string[];
}
```

### Load Balancing

Currently: All agents run on same machine

Future: Route agents to different machines:
```json
{
  "agents": {
    "coder": {
      "host": "worker1.local",
      "working_directory": "/agents/coder"
    },
    "writer": {
      "host": "worker2.local",
      "working_directory": "/agents/writer"
    }
  }
}
```

### Monitoring

Add metrics:
```typescript
- messages_processed_total (by agent)
- processing_duration_seconds (by agent)
- queue_depth (incoming/processing/outgoing)
- agent_active_processing (concurrent count)
```

## ChannelPlugin Bridge

New channels (Zalo OA, Zalo Personal) use the `ChannelPlugin` interface instead of writing to the file queue directly. The queue-processor bridges them:

### Inbound (plugin â†’ queue)

```typescript
// queue-processor.ts â€” called from initPlugins()
function writeMessageToIncoming(msg: IncomingChannelMessage): void {
    if (!msg.chatId?.trim()) return;  // guard: drop if no chatId
    const messageId = crypto.randomUUID();
    const messageData: MessageData = {
        channel: msg.channelId,
        sender: msg.senderName || msg.senderId || 'unknown',
        senderId: msg.chatId.trim(),
        message: msg.content || '',
        timestamp: msg.timestamp || Date.now(),
        messageId,
    };
    const filename = `${msg.channelId}_${messageData.timestamp}_${messageId}.json`;
    fs.writeFileSync(path.join(QUEUE_INCOMING, filename), JSON.stringify(messageData, null, 2));
}
```

`initPlugins()` registers each enabled plugin's `onMessage(writeMessageToIncoming)` handler. Once registered, the plugin's long-poll loop fires `writeMessageToIncoming` for every received message.

### Outbound (queue â†’ plugin)

```typescript
// queue-processor.ts â€” runs every 1s via setInterval
async function deliverPluginResponses(): Promise<void> {
    if (pluginShutdown || pluginDelivering) return;
    pluginDelivering = true;
    // For each file in queue/outgoing/:
    //   if plugin.id matches file.channel:
    //     await plugin.sendMessage(chatId, message)
    //     fs.unlinkSync(file)   â† delete only after successful send
    pluginDelivering = false;
}
```

Files are kept on disk if `sendMessage` throws â€” they will be retried on the next 1s tick.

### Startup Sequence

```
queue-processor.ts main():
  1. initPlugins()              â† instantiate + register plugins
  2. pluginLoader.connectEnabled()  â† start long-poll loops
  3. setInterval(processQueue, 1000)    â† existing queue loop
  4. setInterval(deliverPluginResponses, 1000)  â† new delivery loop
```

### Graceful Shutdown

```typescript
process.on('SIGTERM', async () => {
    pluginShutdown = true;
    clearInterval(processQueueTimer);
    clearInterval(deliverPluginTimer);
    await pluginLoader.disconnectAll();
    process.exit(0);
});
```

### Operational Notes

- **Queue backlog**: Heartbeat messages accumulate in `queue/incoming/` when the daemon is stopped. On restart, avoid processing large backlogs â€” clear stale heartbeat files first to prevent event loop saturation.
- **Event loop health**: If `setInterval` callbacks stop firing while the process is still running at high CPU, the event loop is blocked. Symptoms: log stops updating, zombie child processes. Fix: clear queue, restart daemon.
- **Long-poll 408**: Zalo OA API returns HTTP 408 when `getUpdates` times out with no messages. This is expected behavior â€” the plugin reconnects immediately. Do not treat 408 as an error.

---

## Cross-Team Routing (v1.1.0)

In v1.0.0, `[@agent: msg]` tags only resolve within the current team. In v1.1.0, agents can mention any agent or team across team boundaries.

### Mention Resolution Order

```
[@target: message] in agent response
  â†“
resolveTarget(target, currentAgent, currentTeam, teams, agents)
  1. Same-team agent?  â†’ target (fast path, same as v1.0.0)
  2. Cross-team agent? â†’ target (agent exists but in different team)
  3. Team ID?          â†’ teams[target].leader_agent
  4. Not found         â†’ null (mention silently dropped)
```

### Cross-Team Flow

```
User â†’ @dev "implement login + update requirements"
  â†“
coder (team: dev) implements, responds:
  "Done. [@pm: please update requirements doc for login feature]"
  â†“
resolveTarget("pm") â†’ pm exists, not in dev team â†’ cross-team allowed
  â†“
enqueueInternalMessage(conv.id, "coder", "pm", message, data)
  â†“                                            [CROSS-TEAM] coder (dev) â†’ pm (planning)
pm (team: planning) processes, responds:
  "Requirements updated."
  â†“
conv.pending-- â†’ 0 â†’ completeConversation()
  â†“
Aggregated response delivered to user
```

### Safety Guards

- **Circular detection**: `Conversation.agentsInChain` (Set) tracks all agents who participated. If target already in set â†’ blocked.
- **Delegation depth**: `max_delegation_depth` (default 5) applies across all teams.
- **Conversation cap**: 50-message limit applies to entire conversation including cross-team branches.
- **Self-mention**: Agent cannot mention itself.

### Design Decision: Single Conversation

Cross-team messages stay in the **same conversation** â€” they do not spawn sub-conversations. The `teamContext` remains the originating team for the lifetime of the conversation. This keeps response aggregation simple: all branches (same-team and cross-team) converge into one `completeConversation()` call.

See [ADR-014](adr-zeroclaw-security-patterns.md) for full rationale.

---

## See Also

- [Agent Architecture](agent-architecture.md) - Agent configuration and management
- [Channel Integration Contracts](../03-integrate/channel-integration-contracts.md) - Per-channel API details
- [ADR-014: Cross-Team Routing](adr-zeroclaw-security-patterns.md) - Architecture decision
- [README.md](../README.md) - Main project documentation
- [src/queue-processor.ts](../src/queue-processor.ts) - Implementation
- [src/channels/plugins/](../src/channels/plugins/) - ChannelPlugin implementations
